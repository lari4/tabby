# Tabby Agent Pipelines Documentation

Это полная документация всех пайплайнов и схем работы AI агентов в приложении Tabby. Каждый пайплайн описан с указанием потока данных, используемых промтов и форматов вывода.

---

## 1. Answer/Chat Pipeline - Пайплайн ответов на вопросы

### Назначение
Обработка вопросов пользователя с использованием RAG (Retrieval-Augmented Generation) для предоставления ответов с контекстом из кодовой базы и документации.

### Точка входа
`ee/tabby-webserver/src/service/answer.rs:67` - метод `AnswerService::answer()`

### Схема потока данных

```
┌─────────────────────────────────────────────────────────────────┐
│ ВХОД: User Message + Conversation History + Options             │
└────────────────┬────────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 1: Определение необходимости контекста из кодовой базы    │
│ Файл: answer.rs:93-133                                         │
│ Промт: prompt_tools.rs:39-66 (decide_context_prompt)          │
├────────────────────────────────────────────────────────────────┤
│ → LLM анализирует вопрос                                       │
│ → Определяет нужны ли: file_list и/или snippet                │
│ → Возвращает: { snippet: bool, file_list: bool }              │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 2: Сбор контекста из кода (если необходимо)               │
│ Файл: answer.rs:93-133                                         │
├────────────────────────────────────────────────────────────────┤
│ Если file_list == true:                                        │
│   → RetrievalService::collect_file_list()                      │
│   → Максимум 300 файлов                                        │
│                                                                 │
│ Если snippet == true:                                          │
│   → RetrievalService::collect_relevant_code()                  │
│   → Поиск с использованием BM25 + embeddings (RRF scoring)    │
│   → Возвращает релевантные фрагменты кода                     │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 3: Сбор контекста из документации                         │
│ Файл: answer.rs:136-173                                        │
├────────────────────────────────────────────────────────────────┤
│ → RetrievalService::collect_relevant_docs()                    │
│ → Источники: Issues, PRs, Commits, Pages, Web Docs            │
│ → Поиск через Tantivy index + опционально Serper (web)        │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 4: Генерация связанных вопросов (опционально)             │
│ Файл: answer.rs:176-191                                        │
│ Промт: prompt_tools.rs:16-31 (related_questions_prompt)       │
├────────────────────────────────────────────────────────────────┤
│ → LLM генерирует 3 follow-up вопроса                          │
│ → Каждый вопрос максимум 20 слов                              │
│ → Возвращает: JSON массив вопросов                            │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 5: Формирование финального запроса к LLM                  │
│ Файл: answer.rs:194-214                                        │
│ Промт: utils/mod.rs:129-213 (build_user_prompt)               │
├────────────────────────────────────────────────────────────────┤
│ → Добавление системного промта (личность Tabby)               │
│ → Форматирование пользовательского промта с:                  │
│   • Список файлов (если есть)                                  │
│   • Фрагменты кода с цитированием [[citation:x]]             │
│   • Релевантные документы                                      │
│   • Вопрос пользователя                                        │
│   • Инструкции по формату ответа                              │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 6: Потоковая генерация ответа                             │
│ Файл: answer.rs:216-245                                        │
├────────────────────────────────────────────────────────────────┤
│ → chat.chat_stream(request)                                    │
│ → Стриминг ответа по частям (deltas)                          │
│ → Эмиссия событий ThreadRunItem                               │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ВЫХОД: Stream of ThreadRunItem Events                          │
├────────────────────────────────────────────────────────────────┤
│ • ThreadAssistantMessageReadingCode                            │
│ • ThreadAssistantMessageAttachmentsCodeFileList                │
│ • ThreadAssistantMessageAttachmentsCode                        │
│ • ThreadAssistantMessageAttachmentsDoc                         │
│ • ThreadRelevantQuestions                                      │
│ • ThreadAssistantMessageContentDelta (streaming content)       │
│ • ThreadAssistantMessageCompleted                              │
└────────────────────────────────────────────────────────────────┘
```

### Используемые промты

1. **Системный промт** (`config.rs:467`)
   - Определяет личность Tabby
   - Отправляется как system message

2. **Промт определения контекста** (`prompt_tools.rs:39-66`)
   - Определяет нужен ли snippet и/или file_list
   - Возвращает JSON: `{"snippet": bool, "file_list": bool}`

3. **Промт построения пользовательского запроса** (`utils/mod.rs:129-213`)
   - Добавляет код-сниппеты с цитированием
   - Форматирует список файлов
   - Включает документы
   - Добавляет инструкции по формату ответа

4. **Промт генерации связанных вопросов** (`prompt_tools.rs:16-31`)
   - Генерирует 3 follow-up вопроса
   - Максимум 20 слов каждый
   - Возвращает JSON массив

### Потоки данных между шагами

```
User Message → Decide Context → { snippet: true, file_list: false }
                ↓
Code Search (BM25+Embeddings) → [CodeHit, CodeHit, ...]
                ↓
Doc Search (Tantivy) → [DocHit, DocHit, ...]
                ↓
Build Prompt → "Here are some relevant code snippets:\n```rust\n..."
                ↓
LLM Stream → "Based on the code..." (deltas)
                ↓
Related Questions → ["How does...", "What is...", "Where can..."]
```

### Форматы данных

**Входные данные:**
```rust
struct AnswerRequest {
    messages: Vec<Message>,
    options: AnswerOptions {
        code_query: Option<CodeQuery>,
        doc_query: Option<DocQuery>,
        generate_relevant_questions: bool,
    }
}
```

**Выходные события (stream):**
```rust
enum ThreadRunItem {
    ThreadAssistantMessageReadingCode,
    ThreadAssistantMessageAttachmentsCodeFileList { file_list: Vec<String> },
    ThreadAssistantMessageAttachmentsCode { hits: Vec<CodeSearchHit> },
    ThreadAssistantMessageAttachmentsDoc { hits: Vec<DocSearchHit> },
    ThreadRelevantQuestions { questions: Vec<String> },
    ThreadAssistantMessageContentDelta { delta: String },
    ThreadAssistantMessageCompleted { id: String },
}
```

### Оптимизации и кэширование

- **Поиск по коду:** Использует RRF (Reciprocal Rank Fusion) для объединения BM25 и embedding scores
- **Лимиты:** Максимум 300 файлов в file_list
- **Цитирование:** Система `[[citation:x]]` для отслеживания источников в ответе
- **Потоковая передача:** Ответ отправляется по мере генерации для улучшения UX

---

## 2. Code Completion Pipeline - Пайплайн автодополнения кода

### Назначение
Генерация автодополнения кода в реальном времени с использованием контекста из текущего файла, недавних изменений, деклараций и поиска по кодовой базе.

### Точки входа

**Клиент:** `clients/tabby-agent/src/codeCompletion/index.ts:478` - `CompletionProvider::generateCompletions()`
**Сервер:** `crates/tabby/src/services/completion.rs`

### Схема потока данных (Client → Server → Client)

```
┌─────────────────────────────────────────────────────────────────┐
│ КЛИЕНТСКАЯ ЧАСТЬ: Подготовка контекста                         │
└─────────────────────────────────────────────────────────────────┘

┌────────────────────────────────────────────────────────────────┐
│ ШАГ 1: Построение базового контекста                          │
│ Файл: index.ts:498-523                                         │
├────────────────────────────────────────────────────────────────┤
│ → Извлечение document, position, notebook cells               │
│ → Создание CompletionContext с prefix/suffix lines            │
│ → Определение языка программирования                          │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 2: Проверка кэша                                           │
│ Файл: index.ts:527-529                                         │
├────────────────────────────────────────────────────────────────┤
│ → Вычисление хэша от контекста                                │
│ → Если есть в кэше → возврат закэшированного результата       │
│ → Иначе → продолжение                                          │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 3: Debouncing (умная задержка)                            │
│ Файл: index.ts:547-565                                         │
├────────────────────────────────────────────────────────────────┤
│ → Определение типа триггера (automatic/manual)                │
│ → Расчет задержки на основе среднего времени ответа           │
│ → Отмена предыдущих запросов                                  │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 4: Сбор дополнительного контекста (параллельно)           │
│ Файл: index.ts:568-634                                         │
│ Таймаут: 500ms для automatic, unlimited для manual             │
├────────────────────────────────────────────────────────────────┤
│ A) Workspace Context:                                          │
│    → Git repo info (url, root)                                 │
│                                                                 │
│ B) Git Context:                                                │
│    → Remote URLs, current branch                               │
│                                                                 │
│ C) Declarations (LSP):                                         │
│    → Определения функций/классов (макс. из config)            │
│    → Через Language Server Protocol                           │
│                                                                 │
│ D) Recent Changes Search:                                      │
│    → BM25 поиск по недавно измененным файлам                  │
│    → Релевантные фрагменты кода                               │
│                                                                 │
│ E) Recently Viewed Files:                                      │
│    → Фрагменты из недавно открытых файлов                     │
│                                                                 │
│ F) Editor Options:                                             │
│    → Indent size, tab size, insert spaces                     │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 5: Построение запроса (Segments)                          │
│ Файл: buildRequest.ts                                          │
├────────────────────────────────────────────────────────────────┤
│ → Формирование объекта Segments:                              │
│   • prefix (обрезан до maxPrefixLines)                        │
│   • suffix (обрезан до maxSuffixLines)                        │
│   • filepath (относительно git root или workspace)            │
│   • git_url                                                    │
│   • declarations                                               │
│   • relevant_snippets_from_changed_files                      │
│   • relevant_snippets_from_recently_opened_files              │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 6: HTTP запрос к серверу                                  │
│ Файл: index.ts:584-660                                         │
├────────────────────────────────────────────────────────────────┤
│ → POST /v1/completions или /v1beta/chat/completions           │
│ → Несколько попыток для manual trigger (maxTries)             │
│ → Варьирование temperature для multiple choices               │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌─────────────────────────────────────────────────────────────────┐
│ СЕРВЕРНАЯ ЧАСТЬ: Обработка и генерация                         │
└─────────────────────────────────────────────────────────────────┘

┌────────────────────────────────────────────────────────────────┐
│ ШАГ 7: Обогащение промта контекстом                           │
│ Файл: completion_prompt.rs:32-143                             │
├────────────────────────────────────────────────────────────────┤
│ → Приоритетный сбор сниппетов (макс. 768 chars):              │
│   1. Declarations (из segments)                                │
│   2. Snippets from changed files (из segments)                 │
│   3. Snippets from recently opened files (из segments)         │
│   4. Code search results (минимум 256 chars зарезервировано)  │
│                                                                 │
│ → Code Search (если git_url совпадает с allowed repo):        │
│   • Поиск с BM25 + embeddings                                 │
│   • Merge multi-hit файлов <300 строк в полный файл           │
│                                                                 │
│ → Форматирование сниппетов как комментарии:                   │
│   # Path: file.py                                             │
│   # snippet line 1                                             │
│   # snippet line 2                                             │
│   {original prefix}                                            │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 8: Применение Prompt Template                             │
│ Файл: completion_prompt.rs:32-38                              │
├────────────────────────────────────────────────────────────────┤
│ Если есть prompt_template (зависит от модели):                │
│   → Пример CodeLlama: "<PRE> {prefix} <SUF>{suffix} <MID>"   │
│ Иначе:                                                         │
│   → Просто: "{prefix}"                                         │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 9: LLM Inference                                           │
├────────────────────────────────────────────────────────────────┤
│ → Вызов CodeGeneration или CompletionStream                   │
│ → Возврат raw completion text                                 │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌─────────────────────────────────────────────────────────────────┐
│ КЛИЕНТСКАЯ ЧАСТЬ: Постобработка                                │
└─────────────────────────────────────────────────────────────────┘

┌────────────────────────────────────────────────────────────────┐
│ ШАГ 10: Post-Processing                                        │
│ Файл: index.ts:600-671, postprocess/                          │
├────────────────────────────────────────────────────────────────┤
│ Pre-cache фильтры:                                             │
│ → Базовая фильтрация и форматирование                         │
│                                                                 │
│ Post-cache фильтры:                                            │
│ → Limit scope (удаление кода вне текущей области)             │
│ → Format indentation (корректировка отступов)                 │
│ → Remove duplicates (удаление дубликатов)                     │
│ → Trim space (обрезка пробелов)                               │
│ → Remove linebreaks (удаление лишних переносов)               │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ВЫХОД: CompletionResponse                                      │
├────────────────────────────────────────────────────────────────┤
│ {                                                               │
│   id: string,                                                  │
│   choices: [{                                                  │
│     index: number,                                             │
│     text: string  // Completion text                          │
│   }]                                                           │
│ }                                                              │
└────────────────────────────────────────────────────────────────┘
```

### Используемые промты

1. **FIM Prompt Template** (опционально, зависит от модели)
   - Пример для CodeLlama: `<PRE> {prefix} <SUF>{suffix} <MID>`
   - Определяется в конфигурации модели

2. **Контекстные сниппеты** (встраиваются как комментарии)
   - Форматируются в соответствии с синтаксисом комментариев языка
   - Включают путь к файлу и содержимое

### Приоритизация контекста

```
Доступная квота: 768 символов

┌──────────────────────────┐ Высший приоритет
│ 1. Declarations          │ ← Определения функций/классов из LSP
├──────────────────────────┤
│ 2. Changed Files         │ ← Релевантные фрагменты из измененных файлов
├──────────────────────────┤
│ 3. Recently Opened       │ ← Фрагменты из недавно открытых файлов
├──────────────────────────┤
│ 4. Code Search           │ ← Поиск по кодовой базе (мин. 256 chars)
└──────────────────────────┘ Низший приоритет

Если квота исчерпана, последующие источники игнорируются
```

### Потоки данных

```
Document Context → Build Segments → {prefix, suffix, filepath, git_url, ...}
                                              ↓
                          Parallel Context Collection (500ms timeout):
                                    ├─→ LSP Declarations
                                    ├─→ Recent Changes Search
                                    ├─→ Recently Viewed Files
                                    └─→ Git/Workspace Info
                                              ↓
                                   Build Request Payload
                                              ↓
                                    POST /v1/completions
                                              ↓
                          Server: Enrich with Code Search
                                              ↓
                          Server: Format Prompt with Template
                                              ↓
                                      LLM Inference
                                              ↓
                                  Raw Completion Text
                                              ↓
                          Client: Post-processing Filters
                                              ↓
                                    Final Completion
```

### Форматы данных

**Segments (запрос от клиента к серверу):**
```typescript
interface Segments {
  prefix: string;
  suffix?: string;
  filepath?: string;
  git_url?: string;
  declarations?: Declaration[];
  relevant_snippets_from_changed_files?: Snippet[];
  relevant_snippets_from_recently_opened_files?: Snippet[];
}
```

**CompletionResponse (ответ от сервера):**
```typescript
interface CompletionResponse {
  id: string;
  choices: Array<{
    index: number;
    text: string;
  }>;
}
```

### Оптимизации и кэширование

- **Context-Hash Based Cache:** Кэш основан на хэше контекста (prefix, suffix, snippets)
- **Debouncing:** Умная задержка на основе среднего времени ответа
- **Parallel Context Fetch:** Параллельный сбор контекста с таймаутом 500ms
- **Quota Management:** Приоритизация источников контекста с лимитом 768 chars
- **Code Search Merge:** Объединение multi-hit файлов <300 строк в полный файл
- **Post-processing Pipeline:** Многоступенчатая фильтрация для улучшения качества

---

## 3. Page Generation Pipeline - Пайплайн генерации документации

### Назначение
Автоматическая генерация страниц документации на основе кодовой базы и контекста беседы. Включает создание заголовка, структуры разделов и контента.

### Точка входа
`ee/tabby-webserver/src/service/page.rs:135` - метод `PageServiceImpl::create_run()`

### Схема потока данных

```
┌────────────────────────────────────────────────────────────────┐
│ ВХОД: Conversation Thread + Title Prompt + Options             │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 1: Получение начального контекста через Answer Pipeline   │
│ Файл: page.rs:144-207                                          │
├────────────────────────────────────────────────────────────────┤
│ → Вызов AnswerService::answer() с title_prompt                │
│ → Сбор code & doc attachments из кодовой базы                 │
│ → Построение временного сообщения с контентом ассистента      │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 2: Генерация заголовка страницы                           │
│ Файл: page.rs:486-493, 649-679                                │
│ Промт: prompt_tools.rs:3-11 (prompt_page_title)               │
├────────────────────────────────────────────────────────────────┤
│ → LLM генерирует краткий заголовок                            │
│ → Из предоставленного промта или суммаризации беседы          │
│ → Эмит: PageCreated { id, author_id, title }                  │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 3: Генерация заголовков разделов                          │
│ Файл: page.rs:539-562, 996-1030                               │
│ Промт: prompt_tools.rs:52-73 (prompt_page_section_titles)     │
├────────────────────────────────────────────────────────────────┤
│ → LLM генерирует 3 заголовка разделов                         │
│ → Использует существующие секции + thread messages как context│
│ → Эмит: PageSectionsCreated { sections: [{id, title, pos}] }  │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 4: Генерация введения страницы                            │
│ Файл: page.rs:564-587, 785-816                                │
│ Промт: prompt_tools.rs:13-29 (prompt_page_content)            │
├────────────────────────────────────────────────────────────────┤
│ → LLM генерирует вводный параграф                             │
│ → На основе заголовка страницы + заголовков разделов          │
│ → Эмит (streaming):                                            │
│   • PageContentDelta { delta: string }                         │
│   • PageContentCompleted { id }                                │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 5: Для каждого раздела (цикл)                             │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ├──────────────────────────────────────────────┐
                 │                                               │
                 ▼                                               ▼
┌─────────────────────────────────┐  ┌─────────────────────────────────┐
│ ШАГ 5a: Сбор code attachments   │  │ ШАГ 5b: Сбор doc attachments    │
│ Файл: page.rs:876-913           │  │ Файл: page.rs:915-960           │
├─────────────────────────────────┤  ├─────────────────────────────────┤
│ → Code search по source_id      │  │ → Doc search по doc_query       │
│ → Запрос = заголовок раздела    │  │ → Фильтрация self-references    │
│ → Эмит: PageSectionAttachment-  │  │ → Эмит: PageSectionAttachment-  │
│   Code { id, codes: [hit] }     │  │   Doc { id, doc: [hit] }        │
└────────────────┬────────────────┘  └────────────────┬────────────────┘
                 │                                     │
                 └──────────────┬──────────────────────┘
                                │
                                ▼
                 ┌─────────────────────────────────────────┐
                 │ ШАГ 5c: Генерация контента раздела       │
                 │ Файл: page.rs:963-990, 1032-1065         │
                 │ Промт: prompt_tools.rs:75-92             │
                 │      (prompt_page_section_content)       │
                 ├─────────────────────────────────────────┤
                 │ → LLM генерирует параграф с code        │
                 │ → Учитывает page context + attachments  │
                 │ → Эмит (streaming):                      │
                 │   • PageSectionContentDelta { id, delta }│
                 │   • PageSectionContentCompleted { id }   │
                 └────────────────┬────────────────────────┘
                                  │
                 ┌────────────────┘
                 │ (Повтор для следующего раздела)
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 6: Завершение                                              │
│ Файл: page.rs:641-643                                          │
├────────────────────────────────────────────────────────────────┤
│ → Эмит: PageCompleted { id }                                   │
└────────────────────────────────────────────────────────────────┘
```

### Используемые промты

1. **Page Title Prompt** - Генерация краткого заголовка
2. **Page Section Titles Prompt** - Генерация 3 заголовков разделов
3. **Page Content Prompt** - Генерация вводного параграфа
4. **Page Section Content Prompt** - Генерация контента раздела

### Поток событий (Stream)

```
PageCreated
    ↓
PageSectionsCreated (3 sections)
    ↓
PageContentDelta (streaming intro)
PageContentDelta (streaming intro)
...
PageContentCompleted
    ↓
PageSectionAttachmentCode (section 1)
PageSectionAttachmentDoc (section 1)
PageSectionContentDelta (section 1)
...
PageSectionContentCompleted (section 1)
    ↓
PageSectionAttachmentCode (section 2)
PageSectionAttachmentDoc (section 2)
PageSectionContentDelta (section 2)
...
PageSectionContentCompleted (section 2)
    ↓
... (repeat for section 3)
    ↓
PageCompleted
```

### Оптимизации

- **Потоковая генерация:** Контент генерируется и отправляется по мере создания
- **Контекстная релевантность:** Каждый раздел получает свои code/doc attachments
- **Избежание дублирования:** Инструкции не повторять паттерны из предыдущих разделов

---

## 4. Repository Analysis Pipeline - Анализ структуры репозитория

### Назначение
Генерация вопросов для онбординга новых разработчиков на основе структуры файлов и директорий репозитория.

### Точка входа
`ee/tabby-webserver/src/service/repository/mod.rs:77` - метод `RepositoryService::read_repository_related_questions()`

### Схема потока данных

```
┌────────────────────────────────────────────────────────────────┐
│ ВХОД: Repository Source ID                                     │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 1: Поиск репозитория и проверка доступа                   │
│ Файл: repository/mod.rs:90-92                                  │
├────────────────────────────────────────────────────────────────┤
│ → Lookup repository по source_id                               │
│ → Проверка policy access                                       │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 2: Получение списка файлов                                │
│ Файл: repository/mod.rs:94-105                                 │
├────────────────────────────────────────────────────────────────┤
│ → Вызов RepositoryService::list_files() с лимитом 300         │
│ → Использует tabby_git::list_files()                          │
│ → Возвращает: (Vec<FileEntrySearchResult>, truncated: bool)   │
│                                                                 │
│ Формат каждого файла:                                          │
│ • type: "file" | "dir"                                         │
│ • path: String                                                 │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ШАГ 3: Генерация вопросов                                     │
│ Файл: repository/prompt_tools.rs:27-44                        │
│ Промт: pipeline_related_questions_with_repo_dirs              │
├────────────────────────────────────────────────────────────────┤
│ → Формирование промта с деревом файлов                        │
│ → LLM генерирует 3 вопроса (макс. 10 слов каждый)            │
│ → Кэширование на 30 минут (RELATED_QUESTIONS_CACHE_LIFESPAN) │
└────────────────┬───────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ ВЫХОД: Vec<String> - Список из 3 вопросов                     │
└────────────────────────────────────────────────────────────────┘
```

### Используемый промт

**Repository Questions Prompt:**
```text
You are a helpful assistant that helps the user to ask related questions
about a codebase "{repository_name}".

Here is codebase directory structure:
Type: dir, Path: src/
Type: file, Path: src/main.rs
Type: dir, Path: tests/
...
Note: The file list has been truncated. There may be more files...

Please generate 3 specific questions to help a new engineer understand
this codebase.

Each question should be concise (max 10 words) and focused.
Return only the questions, one per line.
```

### Дополнительные операции

**File Search** (`search_files` method):
- Использует `tabby_git::search_files()` для pattern matching
- Поддерживает glob patterns
- Возвращает top N результатов с индексами совпадений

**Grep** (`grep` method):
- Использует `tabby_git::grep()` для поиска по содержимому
- Возвращает файлы + строки совпадений с byte offsets

### Кэширование

- **Time-based cache:** Кэш на 30 минут для сгенерированных вопросов
- **Per-repository:** Кэш привязан к source_id репозитория

---

